
## AutoGPT: A Powerful Tool for Task Completion Autonomously

Recently, Auto-GPT, a model that enables the strongest language model, GPT-4, to complete tasks autonomously, has caused a sensation in the AI community.

Previously, ChatGPT, which was extremely popular, had one minor flaw in that it required human prompts.

However, Auto-GPT has made a major breakthrough by allowing AI to self-promote, meaning that this AI no longer requires us humans.

![](https://img.ithome.com/newsuploadfiles/2023/4/55ad7b99-e9fd-419e-a06d-81a12c2f8e76.png?x-bce-process=image/format,f_auto "淘汰 ChatGPT 的 Auto-GPT 是炒作？自己跑代码，不需要人类，GitHub 已破 5 万星")

In just seven days, it has received an astonishing number of stars on GitHub (breaking through 50,000) and has attracted the attention of countless open-source communities.

![](https://img.ithome.com/newsuploadfiles/2023/4/20baa2d5-ab0b-4c38-b229-dccf8648a634.png?x-bce-process=image/format,f_auto "淘汰 ChatGPT 的 Auto-GPT 是炒作？自己跑代码，不需要人类，GitHub 已破 5 万星")


Project address: [https://github.com/Torantulino/Auto-GPT](https://github.com/Torantulino/Auto-GPT)

To fully understand how popular Auto-GPT is, just take a look at this comparison chart made by a netizen. In just a few days, it has caught up with a project that had been accumulating stars for nearly 11 years.

![](https://img.ithome.com/newsuploadfiles/2023/4/4772936c-3d27-4eac-b7f9-ccf036c85af3.jpg?x-bce-process=image/format,f_auto "淘汰 ChatGPT 的 Auto-GPT 是炒作？自己跑代码，不需要人类，GitHub 已破 5 万星")

However, while celebrating Auto-GPT, it is also necessary to take a step back and examine its potential shortcomings, as well as the limitations and challenges facing this "AI prodigy".

Recently, Han Xiao, CEO of Jina AI, published a lengthy article "Unveiling Auto-GPT: The Hype and Hard Truth of Production Pitfalls," which delves into whether Auto-GPT is a groundbreaking project or another overhyped AI experiment.

![](https://img.ithome.com/newsuploadfiles/2023/4/e45477ce-6d07-4843-8cfb-cd726a31e2b9.jpg?x-bce-process=image/format,f_auto "淘汰 ChatGPT 的 Auto-GPT 是炒作？自己跑代码，不需要人类，GitHub 已破 5 万星")

### How does Auto-GPT work?

It must be said that Auto-GPT has caused a huge wave in the AI field. It is like giving GPT-4 memory and entities, allowing it to handle tasks independently, and even learn from experience and constantly improve its performance.

To better understand how Auto-GPT works, we can break it down using some simple analogies.

First, imagine Auto-GPT as a resourceful robot.

Every time we assign a task, Auto-GPT will provide a corresponding solution plan. For example, if it needs to browse the Internet or use new data, it will adjust its strategy until the task is completed. This is like having a personal assistant who can handle various tasks such as market analysis, customer service, marketing, finance, etc.

![](https://img.ithome.com/newsuploadfiles/2023/4/d1a2d9cd-1341-48cc-8dbc-7d390274d09b.png?x-bce-process=image/format,f_auto "Is Auto-GPT, which eliminated ChatGPT, a hype? Run the code yourself, no need for humans, GitHub has surpassed 50,000 stars")

Specifically, to run Auto-GPT, we need the following four components:

Architecture:

Auto-GPT is built using powerful GPT-4 and GPT-3.5 language models, which serve as the robot's brain, helping it think and reason.

Autonomous Iteration:

This is like the robot's ability to learn from mistakes. Auto-GPT can review its work, build on past efforts, and use its history to produce more accurate results.

Memory Management:

Integrated with vector databases (a memory storage solution), Auto-GPT can retain context and make better decisions. It's like giving the robot long-term memory, which can remember past experiences.

Multifunctionality:

Auto-GPT's file operations, web browsing, and data retrieval capabilities make it versatile. This is like giving the robot multiple skills to handle a wider range of tasks.

However, these promising prospects may not have yet been translated into actual capabilities that Auto-GPT can achieve.

## Sky-High Cost

The first obstacle to using Auto-GPT in real-world production environments is its high cost.

As the task requires a series of thought iterations to be completed, the model typically exhausts all tokens in every step to provide better reasoning and prompts.

However, GPT-4 tokens are not cheap.

According to OpenAI, for a GPT-4 model with a context window of around 8K, the prompt part costs $0.03 per 1000 tokens, while the result part costs $0.06 per 1000 tokens.

And 1000 tokens roughly correspond to 750 English words.

![](https://img.ithome.com/newsuploadfiles/2023/4/abe48b53-8598-4be2-b0c1-59476e6ab578.png?x-bce-process=image/format,f_auto "淘汰 ChatGPT 的 Auto-GPT 是炒作？自己跑代码，不需要人类，GitHub 已破 5 万星")

Let's break down the cost of each step in the thought chain, assuming that each action exhausts an 8000-token context window, with 80% being prompts (6400 tokens) and 20% being results (1600 tokens).

Prompt cost: 6400 tokens x $0.03 / 1000 tokens = $0.192 Result cost: 1600 tokens x $0.06 / 1000 tokens = $0.096

Therefore, **the cost of each step is: $0.192 + $0.096 = $0.288**

On average, Auto-GPT completes a small task in 50 steps.

Therefore, **the cost of completing a single task is: 50 steps x $0.288 / step = $14.4**

Let's take VueGPT as an example: an AI created by Auto-GPT that aims to create website applications using Vue JS. Let's see one step in its thought chain.

VUEGPT THOUGHTS: Let's start by checking if there are any updates to VueJS. If there are, we can update to the latest version and proceed. Otherwise, we can move on to creating the TODO list website application. REASONING: Starting with the most updated and stable version of the framework will ensure our project has the latest features, bug fixes, and is properly supported. Creating the TODO list website application is our primary goal, so we can move on to that if there are no updates. PLAN:

-   Check for VueJS updates
-   Update to the latest version if there are updates
-   If no updates, move on to creating the TODO list website application CRITICISM: None
- NEXT ACTION: COMMAND = google ARGUMENTS = {'input': 'VueJS latest version update'} Enter 'y' to authorize command, 'y -N' to run N continuous commands, 'n' to exit the program, or enter feedback for VueGPT...

Moreover, this is the scenario where a result is obtained in one go. If it needs to be regenerated, the cost will be even higher.

From this perspective, Auto-GPT is currently unrealistic for most users and organizations.

## Development and Production

At first glance, it seems perfectly fine to spend $14.4 to complete a complex task.

For example, if we ask Auto-GPT to create a Christmas recipe, and then ask it for a Thanksgiving recipe, what do you think will happen?

Auto-GPT will start from scratch using the same thought process, meaning we would need to spend another $14.4 to get the Thanksgiving recipe.

But in reality, the only difference between these two tasks is the holiday.

Since we have already spent $14.4 developing a method to create recipes, it is illogical to spend the same amount of money to adjust the parameters.

Imagine playing Minecraft and having to start building everything from scratch each time. Clearly, this would make the game very boring.

![](https://img.ithome.com/newsuploadfiles/2023/4/8488c1be-6f32-43aa-b557-0fac1c9479d4.png?x-bce-process=image/format,f_auto "淘汰 ChatGPT 的 Auto-GPT 是炒作？自己跑代码，不需要人类，GitHub 已破 5 万星")

This exposes a fundamental problem with Auto-GPT: it cannot distinguish between development and production.

When Auto-GPT completes a task, the development phase is complete. Unfortunately, we cannot "serialize" this series of operations into a reusable function for production.

Therefore, every time a user wants to solve a problem, they must start from the development stage, which is not only time-consuming and laborious but also expensive.

This inefficiency raises questions about the practicality of Auto-GPT in real-world production environments and highlights its limitations in providing sustainable and cost-effective solutions for solving large-scale problems.

## The Quagmire of Loops

However, if $14.4 can really solve the problem, it is still worth it.

But the problem is that Auto-GPT often gets stuck in infinite loops during actual use...

![](https://img.ithome.com/newsuploadfiles/2023/4/673b985b-f021-4e21-abff-4b36774af3b7.png?x-bce-process=image/format,f_auto "淘汰 ChatGPT 的 Auto-GPT 是炒作？自己跑代码，不需要人类，GitHub 已破 5 万星")


![](https://img.ithome.com/newsuploadfiles/2023/4/551f54be-d719-48c8-9c37-2d645c5661f9.png?x-bce-process=image/format,f_auto "淘汰 ChatGPT 的 Auto-GPT 是炒作？自己跑代码，不需要人类，GitHub 已破 5 万星")
So why does Auto-GPT get stuck in these loops?

To understand this, we can think of Auto-GPT as a simple programming language that relies on GPT to solve tasks.

The success of solving tasks depends on two factors: the range of functions available in the programming language and GPT's divide-and-conquer ability to decompose the task into pre-defined programming language. Unfortunately, GPT falls short in both of these areas.

The limited functionality provided by Auto-GPT can be observed in its source code. For example, it provides functions for searching the network, managing memory, interacting with files, executing code, and generating images. However, this limited set of functions narrows the range of tasks that Auto-GPT can effectively perform.

In addition, GPT's ability to decompose and reason is still limited. Although GPT-4 has made significant improvements over GPT-3.5, its reasoning ability is far from perfect, further limiting Auto-GPT's ability to solve problems.

This is similar to trying to build a complex game like StarCraft using Python. Although Python is a powerful language, decomposing StarCraft into Python functions is extremely challenging.

Ultimately, the combination of a limited set of functions and GPT-4's limited reasoning ability creates this quagmire of loops, making it difficult for Auto-GPT to achieve the expected results in many cases.

### Differences between Humans and GPT

The key to Auto-GPT is the use of divide-and-conquer approach. Despite significant improvements in GPT-3.5/4 over its predecessors, its reasoning ability still falls short of human-level when using this approach.

**Insufficient problem decomposition:**

The effectiveness of the divide-and-conquer approach largely depends on the ability to break down complex problems into smaller, more manageable sub-problems. Humans can usually find multiple ways to decompose problems, while GPT-3.5/4 may not have the same level of adaptability or creativity.

**Difficulty in identifying suitable base cases:**

Humans can intuitively select appropriate base cases to arrive at effective solutions. In contrast, GPT-3.5/4 may have difficulty in determining the most effective base cases for a given problem, which can significantly affect the overall efficiency and accuracy of the divide-and-conquer process.

**Insufficient understanding of problem context:**

While humans can use their domain knowledge and background understanding to better tackle complex problems, GPT-3.5/4 is limited by its pre-trained knowledge and may lack the background information necessary for effective problem solving using the divide-and-conquer approach.

**Handling overlapping sub-problems:**

Humans can usually identify and strategically reuse previously computed solutions when dealing with overlapping sub-problems. GPT-3.5/4 may not have the same level of awareness, and may redundantly solve the same sub-problems multiple times, leading to a decrease in the efficiency of the solution.

Vector DB: Excessive solution

Auto-GPT relies on vector databases for faster k-nearest neighbors (kNN) search. These databases retrieve previous chains of thought and integrate them into the current query context to provide a memory effect for GPT.

![](https://img.ithome.com/newsuploadfiles/2023/4/9a37a5da-fc2f-4a75-b00b-b1bfccbf696f.png?x-bce-process=image/format,f_auto "淘汰 ChatGPT 的 Auto-GPT 是炒作？自己跑代码，不需要人类，GitHub 已破 5 万星")


However, considering the constraints and limitations of Auto-GPT, this approach has been criticized as excessive and unnecessarily resource-intensive. The main argument against the use of vector databases stems from the cost constraint associated with Auto-GPT chains of thought.

A 50-step chain of thought costs $14.4, while a 1000-step chain costs even more. Therefore, the size of memory or length of chains of thought rarely exceeds four digits. In this case, exhaustive search of nearest neighbor points (i.e., dot product between a 256-dimensional vector and a 10,000 x 256 matrix) has been proven to be efficient enough, taking less than a second.

In contrast, each GPT-4 call takes approximately 10 seconds to process, so the system's processing speed is actually limited by GPT, not the database.

Although vector databases may have some advantages in specific scenarios, implementing them in the Auto-GPT system to speed up kNN "long-term memory" search seems like an unnecessary luxury and excessive solution.

## Emergence of Intelligent Agent Mechanisms

Auto-GPT introduces an intriguing concept of generating intelligent agents to delegate tasks.

Although this mechanism is still in its infancy, its full potential has not been fully explored. However, there are various ways to enhance and expand the current intelligent agent systems, providing new possibilities for more efficient and dynamic interactions.

![](https://img.ithome.com/newsuploadfiles/2023/4/2d9a191e-d794-46c5-9161-b4bdbed67e17.png?x-bce-process=image/format,f_auto "淘汰 ChatGPT 的 Auto-GPT 是炒作？自己跑代码，不需要人类，GitHub 已破 5 万星")

Asynchronous agents can significantly improve efficiency

One potential improvement is to introduce asynchronous agents. By combining asynchronous waiting patterns, agents can operate concurrently without blocking each other, thereby significantly improving the overall efficiency and response time of the system. This concept is inspired by modern programming paradigms that have adopted asynchronous methods to manage multiple tasks simultaneously.

Another promising direction is to implement communication among intelligent agents. By allowing agents to communicate and collaborate, they can more effectively solve complex problems together. This approach is similar to the IPC concept in programming, where multiple threads/processes can share information and resources to achieve common goals.

## Generative Agents are the Future Direction

As GPT-driven intelligent agents continue to evolve, the future of this innovative approach seems very bright. 

New research such as "Generative Agents: Interactive Simulacra of Human Behavior" emphasizes the potential of agent-based systems in simulating believable human behavior.

The generative agents proposed in the paper can interact in complex and engaging ways, form opinions, initiate dialogues, and even autonomously plan and participate in activities. This work further supports the argument that the intelligent agent mechanism has a promising future in AI development.

By embracing the paradigm shift towards asynchronous programming and promoting communication among intelligent agents, Auto-GPT can open up new possibilities for more efficient and dynamic problem-solving capabilities. By incorporating the architecture and interaction patterns introduced in the "Generative Agents" paper, a fusion of large language models, computing, and interactive intelligent agents can be achieved. This combination has the potential to completely change the way tasks are assigned and executed within AI frameworks, and achieve more realistic simulations of human behavior.

The development and exploration of intelligent agent systems can greatly promote the development of AI applications, providing more powerful and dynamic solutions for complex problems.

## In Summary

In summary, the discussion around Auto-GPT raises important questions about the current state of AI research and the role of public understanding in driving hype around emerging technologies.

As shown above, the limitations in reasoning abilities, excessive use of vector databases, and early stages of agent mechanisms reveal that Auto-GPT still has a long way to go before becoming a practical solution.

The hype around Auto-GPT reminds us that shallow understanding may lead to unrealistic expectations and distortions of AI's true capabilities.

Nevertheless, Auto-GPT does indicate a hopeful direction for the future of AI: generative agent systems.

In conclusion, as Han Xiao summarizes, "Let us learn from the hype around Auto-GPT and cultivate more informed and nuanced conversations about AI research." This way, we can harness the transformative power of generative agent systems to continue pushing the boundaries of AI capabilities and shape a future where technology truly benefits humanity.
